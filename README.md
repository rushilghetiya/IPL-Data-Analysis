# IPL Data Analysis using Apache Spark

## 📌 Project Overview
This project focuses on analyzing **Indian Premier League (IPL) cricket data** using **Apache Spark (PySpark)** on **Databricks**.  
It demonstrates how to process large-scale datasets, perform transformations, and extract meaningful insights such as player performance, team statistics, and venue analysis.

## 🚀 Objectives
- Perform **ETL (Extract, Transform, Load)** on IPL match data.  
- Use **Spark SQL and DataFrame API** to run analytical queries.  
- Generate insights on **players, teams, matches, and venues**.  
- Visualize the results for better interpretation.  

## 🛠️ Tools & Technologies
- **Apache Spark (PySpark)**
- **Databricks Notebook / Jupyter Notebook**
- **Spark SQL & DataFrame API**
- **Python (Pandas, Matplotlib/Seaborn)**
- **Git & GitHub**
- **CSV datasets (IPL matches & players)**

## 📊 Key Insights
- Player performance trends (e.g., most runs, highest wickets).  
- Team statistics across seasons.  
- Toss decision impact on match outcomes.  
- Venue-wise match performance analysis.  

## 📂 Project Structure
ipl-data-analysis-apache-spark-project/
│-- IPL_DATA_ANALYSIS_SPARK.ipynb # Main analysis notebook
│-- data/ # IPL CSV datasets (if available)
│-- README.md # Project documentation

Open the notebook in Databricks or Jupyter.

Upload IPL datasets into the environment.

Run the notebook cells step by step to reproduce the analysis.
